{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CS114_CollectHeadline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1kNegZIdE0SXL7J-bLHZ3sx5P9OM7R3MI",
      "authorship_tag": "ABX9TyNWPAcjsvyJuOTbeaG1L5Dm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Uranium1901/CS111.L21/blob/main/Sarcasm_headline_dataset/CS114_CollectHeadline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBNGBPwl0cIw"
      },
      "source": [
        "# Import thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK8seWiUTI4Q"
      },
      "source": [
        "pip install bs4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApH98losTpUK"
      },
      "source": [
        "pip install requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj-vA2UWTsax"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFAL1w5F0TqN"
      },
      "source": [
        "# Lấy title của 1 bài báo bất kỳ\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWF6QJlTxyFy"
      },
      "source": [
        "#Lấy title từ 1 bài báo\n",
        "def taketitle(url):\n",
        "    reqs = requests.get(url)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        "    for title in soup.find_all('title'):\n",
        "        result=title.get_text()\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiQRzGz40MT9"
      },
      "source": [
        "# Filter lọc url cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ar9uTdLFpMhy"
      },
      "source": [
        "#Hàm lọc những url không cần thiết, chỉ giữ lại url bài báo của trang weeklyworldnews\n",
        "#Ở website này, nhận thấy các url bài báo có chứa đúng 6 dấu '/'\n",
        "def filterweeklyworldnews(url):\n",
        "    count=0\n",
        "    for i in range (len(url)):\n",
        "        if url[i]=='/': \n",
        "            count+=1\n",
        "    if count==6:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRjd7oDtvwrG"
      },
      "source": [
        "#Hàm lọc những url không cần thiết, chỉ giữ lại url bài báo của trang huzlers\n",
        "#Ở website này, nhận thấy các url bài báo có chứa lớn hơn hoặc bằng  3 dấu '-' bên trong url đó\n",
        "def filterhuzlers(url):\n",
        "    count=0\n",
        "    for i in range (len(url)):\n",
        "        if url[i]=='-':\n",
        "            count+=1\n",
        "    if count>=3:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkobcI21SEaA"
      },
      "source": [
        "#Hàm lọc những url không cần thiết, chỉ giữ lại url bài báo của trang thehardtimes\n",
        "#Ở website này, nhận thấy các url bài báo có chứa lớn hơn hoặc bằng  3 dấu '-' bên trong url đó\n",
        "def filterthehardtimes(url):\n",
        "    if ('thehardtimes.net' not in url) or ('the-top-5-comments' in url) : #Lọc những url không chứa thehardtimes.net, url có chứa top 5 comments\n",
        "        return False\n",
        "    count=0\n",
        "    for i in range (len(url)):\n",
        "        if url[i]=='-':\n",
        "            count+=1\n",
        "    if count>=3:\n",
        "        return True\n",
        "    else:\n",
        "        return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jkEIBRGGFm3"
      },
      "source": [
        "#Hàm lọc những url không cần thiết, chỉ giữ lại url bài báo của trang weeklyworldnews\n",
        "#Ở website này, nhận thấy các url bài báo có chứa đúng 7 dấu '/'\n",
        "def filterthepoke(url):\n",
        "  count=0\n",
        "  for i in range (len(url)):\n",
        "    if url[i]=='/':\n",
        "      count+=1\n",
        "  if count==7:\n",
        "    return True\n",
        "  else:\n",
        "    return False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBFOlmG50Hrh"
      },
      "source": [
        "# Định dạng bộ dữ liệu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S2VXaEJfWni"
      },
      "source": [
        "# định dạng mỗi bộ dữ liệu\n",
        "def format(url, title,is_sarcastic):\n",
        "    data={\n",
        "        \"article_link\": url,\n",
        "        \"headline\": title,\n",
        "        \"is_sarcastic\": is_sarcastic\n",
        "    }\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8nnN4-uz1Zm"
      },
      "source": [
        "# Lấy toàn bộ các headline(title) bài báo trên từng Page của website\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6HL1NhmukJf"
      },
      "source": [
        "#Lấy toàn bộ title của các bài báo trên các trang của website huzlers\n",
        "URL = 'https://www.huzlers.com/page/'\n",
        "data=[]\n",
        "# vòng lặp các page\n",
        "for page in range(1,12): \n",
        "    # Tìm kiếm toàn bộ link có trên page\n",
        "    urlpage = URL + str(page) + '/'\n",
        "    reqs = requests.get(urlpage)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        "    # loại bỏ các link giống nhau, lấy title, lưu vào mảng  \n",
        "    preurl=''\n",
        "    for link in soup.find_all('a'):\n",
        "        if link.get('href') is not None:\n",
        "            url=link.get('href')\n",
        "        if filterhuzlers(url) and url!=preurl :\n",
        "            title=taketitle(url)\n",
        "            preurl=url\n",
        "            element= format(url,title,1)\n",
        "            data.append(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYm4so2nwopA"
      },
      "source": [
        "URL = 'https://weeklyworldnews.com/page/'\n",
        "data1=[]\n",
        "for page in range(1,200):\n",
        "  \n",
        "    urlpage = URL + str(page) + '/'\n",
        "    reqs = requests.get(urlpage)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        " \n",
        "    preurl=''\n",
        "    for link in soup.find_all('a'):\n",
        "        url=link.get('href')\n",
        "        if filterweeklyworldnews(url) and url!=preurl :\n",
        "            temp=taketitle(url)\n",
        "            # bỏ đi chuỗi - Weekly World News có trong title của bài báo\n",
        "            if \"- Weekly World News\" in temp:\n",
        "                title=temp[:temp.index('- Weekly World News')-1]\n",
        "            preurl=url\n",
        "            element= format(url,title,1)\n",
        "            data1.append(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoDHkedvq20M"
      },
      "source": [
        "URL = 'https://thehardtimes.net/page/'\n",
        "data2=[]\n",
        "for page in range(1,300):\n",
        "  \n",
        "    urlpage = URL + str(page) + '/'\n",
        "    reqs = requests.get(urlpage)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        "\n",
        "    preurl=''\n",
        "    for link in soup.find_all('a'):\n",
        "        url=link.get('href')\n",
        "        if filterthehardtimes(url) and url!=preurl :\n",
        "            temp=taketitle(url)\n",
        "            if \"- Hard Drive\" in temp:\n",
        "                title=temp[:temp.index('- Hard Drive')]\n",
        "            else:\n",
        "                title=temp\n",
        "            preurl=url\n",
        "            element= format(url,title,1)\n",
        "            data2.append(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IuXQZ3gGAoP"
      },
      "source": [
        "URL = 'https://www.thepoke.co.uk/page/'\n",
        "data3=[]\n",
        "for page in range(1,600):\n",
        "  \n",
        "    urlpage = URL + str(page) + '/'\n",
        "    reqs = requests.get(urlpage)\n",
        "    soup = BeautifulSoup(reqs.text, 'html.parser')\n",
        " \n",
        "    urls = []\n",
        "    preurl=''\n",
        "    for link in soup.find_all('a'):\n",
        "        url=link.get('href')\n",
        "        if filterthepoke(url) and url!=preurl :\n",
        "            temp=taketitle(url)\n",
        "            if \"- The Poke\" in temp:\n",
        "              title=temp[:temp.index('- The Poke')]\n",
        "            else:\n",
        "              title=temp\n",
        "            preurl=url\n",
        "            element= format(url,title,1)\n",
        "            data3.append(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjapAkoh-ae-"
      },
      "source": [
        "#Upload file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxQ117v8zk2f"
      },
      "source": [
        "# Ghi dữ liệu vào file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zBRN1UD5H75"
      },
      "source": [
        "\n",
        "with open('weeklyworldnews.json', 'w') as outfile:\n",
        "    for i in data:\n",
        "        json.dump(i, outfile)\n",
        "        outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kDrBF1hATWi"
      },
      "source": [
        "with open('huzlers.json', 'w') as outfile:\n",
        "    for i in data1:\n",
        "        json.dump(i, outfile)\n",
        "        outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBDI22gFbjrs"
      },
      "source": [
        "with open('thehardtimes.json', 'w') as outfile:\n",
        "    for i in data2:\n",
        "        json.dump(i, outfile,ensure_ascii=False)\n",
        "        outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xlcbD_AF4_I"
      },
      "source": [
        "with open('thepoke.json', 'w') as outfile:\n",
        "    for i in data3:\n",
        "        json.dump(i, outfile,ensure_ascii=False)\n",
        "        outfile.write('\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fgo9xj4qzuQw"
      },
      "source": [
        "# Download file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORcPnJrrzfii"
      },
      "source": [
        "files.download(\"thehardtimes.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAIFHD726yTS"
      },
      "source": [
        "files.download(\"weeklyworldnews.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHCRo0tdAngp"
      },
      "source": [
        "files.download(\"huzlers.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbtG1noYF9HB"
      },
      "source": [
        "files.download(\"thepoke.json\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}